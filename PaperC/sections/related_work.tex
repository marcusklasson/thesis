
\section{Related Work}\label{paperC:sec:related_work}
In this section, we give a brief overview of CL methods, essentially replay-based methods, as well as spaced repetition techniques for human CL.

\vspace{-3mm}
\paragraph{Continual Learning.} Traditional CL can be divided into three main areas, namely regularization-based, architecture-based, and replay-based approaches. Regularization-based methods aim to mitigate catastrophic forgetting by protecting parameters influencing the predictive performance on known tasks from wide changes and use the rest of the parameters for learning new tasks~\citeC{C:adel2019continual, C:chaudhry2018riemannian, C:kirkpatrick2017overcoming, C:li2017learning, C:nguyen2017variational, C:rannen2017encoder, C:schwarz2018progress, C:zenke2017continual}. Architecture-based methods isolate task-specific parameters by either increasing network capacity~\citeC{C:rusu2016progressive, C:yoon2019scalable, C:yoon2017lifelong} or freezing parts of the network~\citeC{C:mallya2018packnet, C:serra2018overcoming} to maintain good performance on previous tasks. 
Replay-based methods mix samples from old tasks with the current dataset to mitigate catastrophic forgetting, where the replay samples are either stored in an external memory~\citeC{C:aljundi2019online, C:chaudhry2019tiny, C:hayes2020remind, C:isele2018selective, C:jin2020gradient, C:lopez2017gradient, C:verwimp2021rehearsal} or generated using a generative model~\citeC{C:shin2017continual, C:van2018generative}. 
Regularization-based approaches and dynamic architectures have been combined with replay-based approaches to methods to overcome their limitations~\citeC{C:buzzega2020dark, C:chaudhry2018riemannian, C:chaudhry2018efficient, C:chaudhry2021using, C:douillard2020podnet, C:ebrahimi2020adversarial, C:joseph2020meta, C:mirzadeh2020linear, C:nguyen2017variational, C:pan2020continual, C:pellegrini2019latent, C:rolnick2018experience, C:von2019continual}. Our work relates most to replay-based methods with external memory which we spend more time on describing in the next paragraph.

\vspace{-3mm}
\paragraph{Replay-based Continual Learning.} A commonly used memory selection strategy of replay samples is random selection. 
%The simplest selection strategy is random selection of examples to store in the memory for replay. 
Much research effort has focused on selecting higher quality samples to store in memory~\citeC{C:aljundi2019gradient, C:borsos2020coresets, C:chaudhry2019tiny, C:chrysakis2020online, C:hayes2019memory, C:isele2018selective, C:lopez2017gradient, C:nguyen2017variational, C:rebuffi2017icarl, C:yoon2021online}. Cahaudrhy et al.~\citeC{C:chaudhry2019tiny} reviews several selection strategies in scenarios with tiny memory capacity, e.g., reservoir sampling~\citeC{C:vitter1985random}, first-in first-out buffer~\citeC{C:lopez2017gradient}, k-Means, and Mean-of-Features~\citeC{C:rebuffi2017icarl}. However, more elaborate selection strategies have been shown to give little benefit over random selection for image classification problems~\citeC{C:chaudhry2018riemannian, C:hayes2020remind}. More recently, there has been work on compressing raw images to feature representations to increase the number of memory examples for replay~\citeC{C:hayes2020remind, C:iscen2020memory, C:pellegrini2019latent}. 
Selecting the time to replay old tasks has mostly been ignored in the literature, with an exception in~\citeC{C:aljundi2019online} which replays memory samples that would most interfere with a foreseen parameter update. 
Our replay scheduling approach differs from the above mentioned works since we focus on learning to select which tasks to replay. Nevertheless, our scheduling can be combined with any selection strategy and replay method. 


\vspace{-3mm}
\paragraph{Human Continual Learning.} Humans are CL systems in the sense of learning tasks and concepts sequentially. Furthermore, humans have the ability to memorize experiences but forgets learned knowledge gradually rather than catastrophically~\citeC{C:french1999catastrophic}. Different learning techniques have been suggested for humans to memorize better~\citeC{C:dunlovsky2013improving, C:willis2007review}. 
An example is spaced repetition where time intervals between rehearsal are gradually increased to improve long-term memory retention~\citeC{C:dempster1989spacing}, where the earliest documented works are from Ebbinghaus~\citeC{C:ebbinghaus2013memory}. 
Further studies have shown that memory training schedules with adjusted spaced repetition are better at preserving memory than using uniformly spaced rehearsal times~\citeC{C:hawley2008comparison, C:landauer1978optimum}. 
Several works in CL with neural networks are inspired by human learning techniques, including spaced repetition~\citeC{C:amiri2017repeat, C:feng2019spaced, C:smolen2016right}, sleep mechanisms~\citeC{C:ball2020study, C:mallya2018packnet, C:schwarz2018progress}, 
and memory reactivation~\citeC{C:hayes2020remind, C:van2020brain}. Replay scheduling is also inspired by spaced repetition, where we learn schedules of which tasks to replay at different times. 


