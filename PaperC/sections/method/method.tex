
\section{Method}\label{paperC:sec:method}

In this section, we describe our new problem setting of CL where historical data are available while the processing time is limited when learning new tasks. 
In Section \ref{paperC:sec:problem_setting} and \ref{paperC:sec:replay_scheduling_in_continual_learning}, we present the considered problem setting, as well as our idea of learning schedules over which tasks to replay at different time steps to mitigate catastrophic forgetting.
We use MCTS~\citeC{C:coulom2006efficient} in an ideal CL environment that searches for good replay schedules to show the importance of replay scheduling in CL (Section \ref{paperC:sec:mcts_for_replay_scheduling}). 


\input{PaperC/sections/method/problem_setting}

 %%% RS-MCTS EXAMPLE FIGURE 
\begin{figure}[t]
\centering 
\setlength{\figwidth}{.77\textwidth}
\setlength{\figheight}{.3\textheight}
\input{PaperC/figures/rs_mcts_tree_example2}
\vspace{-2mm}
\caption{Tree-shaped action space of possible replay memory compositions with size $M=8$ at every task from the discretization method described in Section \ref{sec:replay_scheduling_in_continual_learning} for Split MNIST. A replay schedule is represented as a path traversal of different replay memory compositions from task 1 to task 5. 
}
\vspace{-3mm}
\label{fig:replay_scheduling_mcts_tree_example}
\end{figure}

\input{PaperC/sections/method/replay_scheduling_in_continual_learning}

\input{PaperC/sections/method/mcts_for_replay_schedules}






