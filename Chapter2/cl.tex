\section{Continual Learning in Neural Networks}
\label{sec:continual_learning}

A common assumption in machine learning is that the data comes from stationary distributions such that the properties of the data are the same over time. However, this assumption may complicate deployments in real-world applications where variations in the data is common and the data seen during deployment can be very different from the data used for training. Such models has to be capable of learning from experiences online and update its knowledge about new concepts that are encountered during the lifespan. Furthermore, as the model is operating in an online manner, the model has to adapt fast when learning new knowledge to minimize the time that the system has to be down during training. These requirements has lead to research in Continual Learning (CL)~\cite{delange2021continual, parisi2019continual} where the goal is to push neural networks closer to how humans and animals are learning various tasks during their lifespan.

Next, we introduce some notation of the problem setting in CL for image classification. We let a neural network $f_{\vtheta}$, parameterized by $\vtheta$, learn $T$ tasks sequentially given their corresponding task datasets $\gD_1, \dots, \gD_T$ arriving in order. The $t$-th dataset $\gD_t = \{(\vx_{t}^{(i)}, y_{t}^{(i)})\}_{i=1}^{N_{t}}$ consists of $N_t$ samples where $\vx_{t}^{(i)}$ and $y_{t}^{(i)}$ are the $i$-th data point and class label respectively. The training objective at task $t$ is given by 
\begin{align}
	\underset{\vtheta}{\text{min}} \sum_{i=1}^{N_t} \ell(f_{\vtheta}(\vx_t^{(i)}), y_{t}^{(i)}),
\end{align}
where $\ell(\cdot)$ is the loss function, e.g., cross-entropy loss in image classification problems. Since $\gD_t$ is only accessible at time step $t$, the network $f_{\vtheta}$ is at risk of \textit{catastrophically forgetting} the previous $t-1$ tasks when learning the current task. 
%Replay-based continual learning methods mitigate the forgetting of old tasks by storing old examples in an external replay memory, that is mixed with the current task dataset during training. Next, we describe our method for constructing this replay memory.  

There are several desired properties of CL systems mentioned in~\cite{schwarz2018progress} to enhance their utility. Firstly, they should be capable of retaining already existing knowledge to mitigate the catastrophic forgetting effect that neural networks are susceptible to when trained in CL settings. Secondly, we hope that the model can benefit from the previously learned tasks to ease the learning of new tasks, which is referred to as \textit{forward transfer}. Moreover, we wish that learning new tasks can have positive influence on the performance of old tasks which is called \textit{backward transfer}. It also needs to be \textit{scalable} to a large number of tasks that could be encountered during its life time. Finally, it should ideally be capable of learning without the need for task labels as there might be unclear task boundaries when the model is deployed. 

Research in CL can be divided into three main areas, namely regularization-based, architecture-based, and replay-based approaches. Regularization-based methods aim to mitigate catastrophic forgetting by protecting parameters influencing the predictive performance from wide changes and use the rest of the parameters for learning the new tasks~\cite{adel2019continual, chaudhry2018riemannian, kirkpatrick2017overcoming, li2017learning, nguyen2017variational, rannen2017encoder, schwarz2018progress, zenke2017continual}. Architecture-based methods isolate task-specific parameters by either increasing network capacity~\cite{rusu2016progressive, yoon2019scalable, yoon2017lifelong} or freezing parts of the network~\cite{mallya2018packnet, serra2018overcoming} to maintain good performance on previous tasks. 
Replay-based methods mix samples from old tasks with the current dataset to mitigate catastrophic forgetting, where the replay samples are either stored in an external memory~\cite{chaudhry2019tiny, hayes2020remind, isele2018selective, lopez2017gradient} or generated using a generative model~\cite{shin2017continual, van2018generative}. 
Regularization-based approaches and dynamic architectures have been combined with replay-based approaches to methods to overcome their limitations~\cite{chaudhry2018riemannian, chaudhry2018efficient, douillard2020podnet, ebrahimi2020adversarial, joseph2020meta, mirzadeh2020linear, nguyen2017variational, pan2020continual, pellegrini2019latent, rolnick2018experience, von2019continual}. In general, these methods share the goal of mitigating catastrophic forgetting in various ways and then they can have additional goals related to the other desired properties on forward- and backward transfer, task scalability, and avoiding the need for task labels. 